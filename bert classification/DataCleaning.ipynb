{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"DataCleaning.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"ng3DNUrWJm0h"},"source":["import pandas as pd\n","import numpy as np\n","from sqlalchemy import create_engine as ce\n","from sqlalchemy import inspect\n","from pathlib import Path"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L3seTTdhJm0l"},"source":["# Part 0: Loading the files"]},{"cell_type":"code","metadata":{"id":"TaIcbnEaJm0m"},"source":["DATA = Path(\"books.db\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ggj514ycJm0n"},"source":["engine = ce(\"sqlite:///\"+str(DATA))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vdiqdghTJm0o"},"source":["inspector = inspect(engine)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8tqdGQInJm0o","outputId":"dc9e2f38-8bd4-4293-ad60-b482669af945"},"source":["print(inspector.get_table_names())"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["['authors', 'book_file', 'book_original', 'books', 'text_files']\n"]}]},{"cell_type":"code","metadata":{"id":"nBGeobVKJm0p"},"source":["books_df = pd.read_sql(\"books\", con = engine)\n","author_df = pd.read_sql(\"authors\", con = engine)\n","book_file_df = pd.read_sql(\"book_file\", con = engine)\n","text_file_df = pd.read_sql(\"text_files\", con = engine)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xTOMN4eFJm0q"},"source":["# Part 1: Convert book files into sentences"]},{"cell_type":"code","metadata":{"id":"WdmU16y8Jm0r"},"source":["# Convert the book text into lowercase\n","filtered_text = pd.DataFrame()\n","filtered_text['text'] = text_file_df['text'].apply(lambda x: list(filter(None, x.lower().split(\"\\n\"))))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bMCE0WOsJm0s"},"source":["gender_lst = ['woman', 'women', 'female', 'she', 'her', 'hers', 'man', 'men', 'male', 'he', 'his', 'him']\n","woman_lst = ['woman', 'women', 'female', 'she', 'her', 'hers']\n","man_lst = ['man', 'men', 'male', 'he', 'his', 'him']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WRwcngR4Jm0s"},"source":["# Filter out the sentences that contain gender words\n","filtered_text['text'] = filtered_text['text'].apply(lambda x: [sentence for sentence in x if any(word in sentence.split() for word in gender_lst)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nXYP_UX0Jm0s"},"source":["sentence_count = 0\n","for index, row in filtered_text.iterrows():\n","    sentence_count += len(row['text'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O72nbRN-Jm0t","outputId":"cac1b4f2-9441-4180-e531-96f4fea16520"},"source":["sentence_count"],"execution_count":null,"outputs":[{"data":{"text/plain":["2005472"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"gWv6esI-Jm0t","outputId":"20349972-7115-4018-a420-6fd7f0c46739"},"source":["import nltk\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to\n","[nltk_data]     /Users/jiemintang/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"code","metadata":{"id":"H8TNHAtCJm0t","outputId":"1fccbb4b-2732-4351-d3fb-b459d0862ad7"},"source":["nltk.download('punkt')"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/jiemintang/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"U92-uLjUJm0u"},"source":["wnl = WordNetLemmatizer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2hdhaFzHJm0u"},"source":["home_category = ['home', 'homes', 'domestic', 'household', 'households', 'chore', 'chores', 'family', 'families']\n","work_category = ['work', 'works', 'worked', 'labor', 'worker', 'workers', 'economy', 'trade', 'trades', \\\n","                 'business', 'businesses', 'job', 'jobs', 'company', 'companies', 'industry', 'industries', \\\n","                 'pay', 'pays', 'paid', 'working', 'salary', 'salaries', 'wage', 'wages']\n","achievement_category = ['power', 'authority', 'authorities', 'achievement', 'control', 'controls', 'controlled',\\\n","                        'won', 'win', 'wins', 'powerful', 'success', 'succeed', 'succeeded', 'successful',\\\n","                        'better', 'effort', 'efforts', 'plan', 'plans', 'planned', 'try', 'tries', 'tried', 'leader']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aM-z9bljJm0u"},"source":["filtered_text['text'] = filtered_text['text'].apply(lambda x: [sentence for sentence in x \\\n","    if any(word in sentence.split() for word in home_category)\\\n","    or any(word in sentence.split() for word in work_category)\\\n","    or any(word in sentence.split() for word in achievement_category)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I5H7AsJ1Jm0v"},"source":["sentence_count = 0\n","for index, row in filtered_text.iterrows():\n","    sentence_count += len(row['text'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ocxPqEgGJm0v","outputId":"53057178-b59c-4fed-89c5-b420caaf22ff"},"source":["sentence_count"],"execution_count":null,"outputs":[{"data":{"text/plain":["67701"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"AEbGNEcuJm0v"},"source":["sentences_df = pd.DataFrame(columns = ['text', 'gender', 'category'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZImco1BnJm0w"},"source":["# Building the sentences with labels\n","for index, row in filtered_text.iterrows():\n","    for i in range(len(row['text'])):\n","        if any(word in row['text'][i].split() for word in woman_lst) and \\\n","           any(word in row['text'][i].split() for word in man_lst):\n","            break\n","        elif any(word in row['text'][i].split() for word in woman_lst):\n","            curr_categories = []\n","            if any(word in row['text'][i].split() for word in home_category):\n","                curr_categories.append('home')\n","            if any(word in row['text'][i].split() for word in work_category):\n","                curr_categories.append('work')\n","            if any(word in row['text'][i].split() for word in achievement_category):\n","                curr_categories.append('achievement')\n","                \n","            sentences_df = sentences_df.append({'text': row['text'][i], 'gender' : 'woman', 'category': curr_categories}, ignore_index = True)\n","        elif any(word in row['text'][i].split() for word in man_lst):\n","            curr_categories = []\n","            if any(word in row['text'][i].split() for word in home_category):\n","                curr_categories.append('home')\n","            if any(word in row['text'][i].split() for word in work_category):\n","                curr_categories.append('work')\n","            if any(word in row['text'][i].split() for word in achievement_category):\n","                curr_categories.append('achievement')\n","\n","            sentences_df = sentences_df.append({'text': row['text'][i], 'gender' : 'man', 'category': curr_categories}, ignore_index = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PmYz_3dbJm0w","outputId":"7ec85751-2c0e-4dc4-cdcc-e7d16fd2dfc3"},"source":["sentences_df.head(10)"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>gender</th>\n","      <th>category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>till with that wealth he pays his soldiery.</td>\n","      <td>man</td>\n","      <td>[work]</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>better to die than leave his banneret.\"</td>\n","      <td>man</td>\n","      <td>[achievement]</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>yet which might win they knew not, in his thou...</td>\n","      <td>man</td>\n","      <td>[achievement]</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>then find him men, his company are worth.\"</td>\n","      <td>man</td>\n","      <td>[work]</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>at the sword's point he yet shall pay our meed.\"</td>\n","      <td>man</td>\n","      <td>[work]</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>no man on earth has more nor better found.</td>\n","      <td>man</td>\n","      <td>[achievement]</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>better he loves murder and treachery</td>\n","      <td>man</td>\n","      <td>[achievement]</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>soon as rollant his senses won and knew,</td>\n","      <td>man</td>\n","      <td>[achievement]</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>i won for him with thee anjou, bretaigne,</td>\n","      <td>man</td>\n","      <td>[achievement]</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>and won for him with thee peitou, the maine,</td>\n","      <td>man</td>\n","      <td>[achievement]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text gender       category\n","0        till with that wealth he pays his soldiery.    man         [work]\n","1            better to die than leave his banneret.\"    man  [achievement]\n","2  yet which might win they knew not, in his thou...    man  [achievement]\n","3         then find him men, his company are worth.\"    man         [work]\n","4   at the sword's point he yet shall pay our meed.\"    man         [work]\n","5         no man on earth has more nor better found.    man  [achievement]\n","6               better he loves murder and treachery    man  [achievement]\n","7           soon as rollant his senses won and knew,    man  [achievement]\n","8          i won for him with thee anjou, bretaigne,    man  [achievement]\n","9       and won for him with thee peitou, the maine,    man  [achievement]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"XGxrB4lIJm0w","outputId":"ff1b3970-e0f8-45c5-d860-70985e71ca0c"},"source":["sentences_df.groupby('gender').count()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>category</th>\n","    </tr>\n","    <tr>\n","      <th>gender</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>man</td>\n","      <td>36030</td>\n","      <td>36030</td>\n","    </tr>\n","    <tr>\n","      <td>woman</td>\n","      <td>10024</td>\n","      <td>10024</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         text  category\n","gender                 \n","man     36030     36030\n","woman   10024     10024"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"YQNGANukJm0x"},"source":["sentences_df.to_csv('cleaned_data.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cBA3y7C9Jm0x"},"source":["# Extra processing - Not Used"]},{"cell_type":"code","metadata":{"id":"jS6vREP9Jm0x"},"source":["pre1980_author_df = author_df[author_df['death'] < int(1980)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"euyDMHgfJm0x"},"source":["post1980_author_df = author_df[author_df['born'] >= int(1950)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IyDrW_zrJm0x","outputId":"3a491e4d-79cb-43e0-8216-fc4668031af9"},"source":["post1980_author_df"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>author</th>\n","      <th>born</th>\n","      <th>death</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>Aesop</td>\n","      <td>10000</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>13</td>\n","      <td>Anatole France</td>\n","      <td>10000</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>92</td>\n","      <td>Frederick Engles</td>\n","      <td>10000</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>95</td>\n","      <td>Friedrich Wieser</td>\n","      <td>10000</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>96</td>\n","      <td>Fyodor Dostoevsky</td>\n","      <td>10000</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <td>129</td>\n","      <td>129</td>\n","      <td>Homer</td>\n","      <td>10000</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>140</td>\n","      <td>Jacob Vanderlint</td>\n","      <td>10000</td>\n","      <td>1740</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>200</td>\n","      <td>Nan</td>\n","      <td>10000</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <td>212</td>\n","      <td>212</td>\n","      <td>P. Cornelius Tacitus</td>\n","      <td>10000</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <td>216</td>\n","      <td>216</td>\n","      <td>Plato</td>\n","      <td>10000</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <td>217</td>\n","      <td>217</td>\n","      <td>Plutarch</td>\n","      <td>10000</td>\n","      <td>126</td>\n","    </tr>\n","    <tr>\n","      <td>222</td>\n","      <td>222</td>\n","      <td>Richard Cantillon</td>\n","      <td>10000</td>\n","      <td>1734</td>\n","    </tr>\n","    <tr>\n","      <td>254</td>\n","      <td>254</td>\n","      <td>Thomas Malory</td>\n","      <td>10000</td>\n","      <td>1471</td>\n","    </tr>\n","    <tr>\n","      <td>261</td>\n","      <td>261</td>\n","      <td>Thucydides</td>\n","      <td>10000</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <td>263</td>\n","      <td>263</td>\n","      <td>Titus Lucretius Carus</td>\n","      <td>10000</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <td>277</td>\n","      <td>277</td>\n","      <td>William And Ellen Craft</td>\n","      <td>10000</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>290</td>\n","      <td>Xenophon</td>\n","      <td>10000</td>\n","      <td>10000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     index                   author   born  death\n","3        3                    Aesop  10000  10000\n","13      13           Anatole France  10000  10000\n","92      92         Frederick Engles  10000  10000\n","95      95         Friedrich Wieser  10000  10000\n","96      96        Fyodor Dostoevsky  10000  10000\n","129    129                    Homer  10000  10000\n","140    140         Jacob Vanderlint  10000   1740\n","200    200                      Nan  10000  10000\n","212    212     P. Cornelius Tacitus  10000  10000\n","216    216                    Plato  10000  10000\n","217    217                 Plutarch  10000    126\n","222    222      Richard Cantillon    10000   1734\n","254    254            Thomas Malory  10000   1471\n","261    261               Thucydides  10000  10000\n","263    263    Titus Lucretius Carus  10000  10000\n","277    277  William And Ellen Craft  10000  10000\n","290    290                 Xenophon  10000  10000"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"2PhypNQwJm0y"},"source":[""],"execution_count":null,"outputs":[]}]}